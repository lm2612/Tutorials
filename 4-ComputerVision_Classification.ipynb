{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will build convolutional neural network to classify pets using the Oxford pet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data - this is a pytorch built-in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms.v2 import ToTensor, ToPILImage, Compose, CenterCrop, Resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transforms\n",
    "img_to_tensor = ToTensor()\n",
    "tensor_to_img = ToPILImage()\n",
    "crop = CenterCrop(360)        # crop all images to same size (360 x 360)\n",
    "resize = Resize(128)          # resize so images are smaller / computationally cheaper\n",
    "\n",
    "# the Oxford pet dataset is labelled by 37 breeds of cats and dogs, but we \n",
    "# will use the dataset to predict species cat (0) or dog (1) \n",
    "# manually define transform to convert breed id (1-37) to species id (0/1)\n",
    "cat_breed_ids = [0, 5, 6, 7, 9, 11, 20, 23, 26, 27, 32, 33]\n",
    "\n",
    "def breed2species(breedid):\n",
    "    if breedid in cat_breed_ids:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data = datasets.OxfordIIITPet(\n",
    "    root=\"./\",\n",
    "    download=False,\n",
    "    target_types = \"category\",\n",
    "    transform=Compose([img_to_tensor, crop, resize]),\n",
    "    target_transform=breed2species\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = torch.utils.data.random_split(data, lengths=[0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = training_data[1120]\n",
    "print(y)\n",
    "tensor_to_img(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the dataset\n",
    "Split into training, validation and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(training_data, \n",
    "                                         shuffle=True,\n",
    "                                         batch_size=128)\n",
    "dataloader_validation = torch.utils.data.DataLoader(validation_data, \n",
    "                                         shuffle=True,\n",
    "                                         batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data), len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader))\n",
    "print(y)\n",
    "tensor_to_img(X_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "Create a convolutional network with 3 layers. \n",
    "First, explore what the convolutions are doing. \n",
    "\n",
    "Here is our first convolutional layer, that includes our convolution, RELU, BatchNorm and Pooling. Its good to check the size of the tensor.\n",
    "Look at the docs here: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "Always need in_channels, out_channels, and kernel_size. You can also define stride and padding. Try some different choices and compare what the output shape is like. Explore what some output looks like for a few different channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels=3, \n",
    "                      out_channels=3, \n",
    "                      kernel_size=3,\n",
    "                      padding=0),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.BatchNorm2d(3),\n",
    "      torch.nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_conv = conv_layer_1(X_batch)  # (BATCH, CHANNELS, WIDTH, HEIGHT)\n",
    "print(X_test_conv.shape)\n",
    "tensor_to_img(X_test_conv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the size of our tensor has changed: its smaller because of the convolution and pooling. We can see some features from the convolution, that highlight regions of the image where the gradient is quickly changing, which shows us outlines of objects in the image. For the second convolutional layer, we will use the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels = 3,\n",
    "                      out_channels = 3,\n",
    "                      kernel_size = 3,\n",
    "                      padding=0),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.BatchNorm2d(3),\n",
    "      torch.nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_conv = conv_layer_2(X_test_conv)  # (BATCH, CHANNELS, WIDTH, HEIGHT)\n",
    "print(X_test_conv.shape)\n",
    "tensor_to_img(X_test_conv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_3 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(in_channels = 3,\n",
    "                      out_channels = 3,\n",
    "                      kernel_size = 3,\n",
    "                      padding=0),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.BatchNorm2d(3),\n",
    "      torch.nn.MaxPool2d(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_conv = conv_layer_3(X_test_conv)  # (BATCH, CHANNELS, WIDTH, HEIGHT)\n",
    "print(X_test_conv.shape)\n",
    "tensor_to_img(X_test_conv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will pass our tensor through a fully connected linear layer to get our output. Our tensor is currently 3 channels by 14 in height and 14 in width, so we need to flatten this before it can go into a linear layer. The number of features going into the linear layer is 3 x 14 x 14 and the number of outputs is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.nn.Sequential(\n",
    "      torch.nn.Flatten(),\n",
    "      torch.nn.Linear(in_features=3*14*14, out_features=1),\n",
    "      torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(X_test_conv).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model \n",
    "Create a convolutional neural network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create CNN in layers\n",
    "        self.conv_layer_1 = torch.nn.Sequential(\n",
    "          torch.nn.Conv2d(in_channels=3, \n",
    "                          out_channels=3, \n",
    "                          kernel_size=3,\n",
    "                          padding=0),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.BatchNorm2d(3),\n",
    "          torch.nn.MaxPool2d(2))\n",
    "        self.conv_layer_2 = torch.nn.Sequential(\n",
    "          torch.nn.Conv2d(in_channels = 3,\n",
    "                          out_channels = 3,\n",
    "                          kernel_size = 3,\n",
    "                          padding=0),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.BatchNorm2d(3),\n",
    "          torch.nn.MaxPool2d(2))\n",
    "        self.conv_layer_3 = torch.nn.Sequential(\n",
    "          torch.nn.Conv2d(in_channels = 3,\n",
    "                          out_channels = 3,\n",
    "                          kernel_size = 3,\n",
    "                          padding=0),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.BatchNorm2d(3),\n",
    "          torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "          torch.nn.Flatten(),\n",
    "          torch.nn.Linear(in_features=3*14*14, out_features=1),\n",
    "          torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of SimpleNet and check we can call the function .forward on our first batch\n",
    "my_network = ConvNet()\n",
    "pred_batch = my_network(X_batch)\n",
    "# Check the output is the correct size\n",
    "print(pred_batch.shape)\n",
    "#assert(pred_batch.shape == y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_batch, y_batch.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up loss function and optimiser\n",
    "Decide on a suitable loss function for a classifier.\n",
    "\n",
    "We will use CrossEntropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.BCELoss()\n",
    "loss = loss_function(pred_batch.squeeze(), y_batch.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we also need to set up our optimiser and provide our network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = sum( sum(p.size()) for p in my_network.parameters())\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = torch.optim.SGD(params = my_network.parameters(), lr=0.1)\n",
    "optimiser = torch.optim.Adam(params = my_network.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop \n",
    "Start the training loop - it will look similar to our training loop from this morning. You can expect it to take several minutes to run - that's why its always sensible to check you can run a smaller version of it first with a subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "num_epochs = 10\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "for epoch in range(num_epochs):\n",
    "    my_network.train()\n",
    "    training_loss = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimiser.zero_grad()\n",
    "        pred_batch = my_network(X_batch)\n",
    "        loss = loss_function(pred_batch.squeeze(), y_batch.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # Update optimiser\n",
    "        optimiser.step()\n",
    "        \n",
    "        # Add loss to training_loss\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    # Add MSE losses to our list for plotting\n",
    "    training_loss = training_loss / len(dataloader)\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    # validation\n",
    "    my_network.eval()\n",
    "    validation_loss = 0\n",
    "    for X_batch, y_batch in dataloader_validation:\n",
    "        optimiser.zero_grad()\n",
    "        pred_batch = my_network(X_batch)\n",
    "        loss = loss_function(pred_batch.squeeze(), y_batch.float())\n",
    "        # Add loss to validation_loss\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    # Add MSE losses to our list for plotting\n",
    "    validation_loss = validation_loss / len(dataloader_validation)\n",
    "    validation_losses.append(validation_loss)\n",
    "    \n",
    "    # After every  epoch print mean losses\n",
    "    if epoch%1 ==0:\n",
    "        print(f\"After epoch {epoch}: Training loss={training_loss:.2f}, validation loss={validation_loss:.2f}\")\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.plot(training_losses, label=\"training\")\n",
    "plt.plot(validation_losses,  label=\"validation\")\n",
    "plt.legend()\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(pred_batch):\n",
    "    return torch.where(pred_batch > 0.5, 1.0, 0.0)\n",
    "\n",
    "def label(y):\n",
    "    if y < 0.5:\n",
    "        return \"cat\"\n",
    "    elif y > 0.5:\n",
    "        return \"dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader))\n",
    "pred_batch = my_network(X_batch)\n",
    "fig, axs = plt.subplots(8, 4, figsize=(10, 24))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(32):\n",
    "    y_label = label(y_batch[i])\n",
    "    pred_label = label(pred_batch[i])\n",
    "    axs[i].imshow(tensor_to_img(X_batch[i]))\n",
    "    axs[i].set_title(f\"{pred_label} (true {y_label})\", \n",
    "                     color=\"blue\" if pred_label is y_label else \"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader_validation))\n",
    "pred_batch = my_network(X_batch)\n",
    "fig, axs = plt.subplots(8, 4, figsize=(10, 24))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(32):\n",
    "    y_label = label(y_batch[i])\n",
    "    pred_label = label(pred_batch[i])\n",
    "    axs[i].imshow(tensor_to_img(X_batch[i]))\n",
    "    axs[i].set_title(f\"{pred_label} (true {y_label})\", \n",
    "                     color=\"blue\" if pred_label is y_label else \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've built your own cat/dog classifier. Now try and improve upon it with more data. You could also try and predict the breed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check convolutional layers\n",
    "What are the convolutional layers doing after training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader_validation))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "axs = axs.flatten()\n",
    "axs[0].imshow(tensor_to_img(X_batch[0]))\n",
    "X_conv = my_network.conv_layer_1(X_batch)\n",
    "axs[1].imshow(tensor_to_img(X_conv[0]))\n",
    "X_conv = my_network.conv_layer_2(X_conv)\n",
    "axs[2].imshow(tensor_to_img(X_conv[0]))\n",
    "X_conv = my_network.conv_layer_3(X_conv)\n",
    "axs[3].imshow(tensor_to_img(X_conv[0]))\n",
    "print(my_network.classifier(X_conv)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
