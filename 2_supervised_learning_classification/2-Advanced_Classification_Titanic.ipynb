{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d5af9f",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lm2612/Tutorials/blob/main/2_supervised_learning_classification/2-Advanced_Classification_Titanic.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c259f",
   "metadata": {},
   "source": [
    "## Titanic: Machine learning from disaster\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this tutorial, we will use passenger data to predict who survived the shipwreck and also use our predictive model to answer the question: \"what sorts of people were more likely to survive?\". We will focus on passenger age, gender and socio-economic class). You can read more about the Titanic dataset [here](https://www.kaggle.com/c/titanic/overview).\n",
    "\n",
    "This is the advanced version of the tutorial, where we will learn how to build our own classifiers.\n",
    "First, import packages and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73896b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc34d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook running locally. Using local filepath = ./titanic.csv\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    filepath = \"https://raw.githubusercontent.com/lm2612/Tutorials/refs/heads/main/2_supervised_learning_classification/titanic.csv\"\n",
    "    print(f\"Notebook running in google colab. Using raw github filepath = {filepath}\")\n",
    "\n",
    "else:\n",
    "    filepath = \"./titanic.csv\"\n",
    "    print(f\"Notebook running locally. Using local filepath = {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717deb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4296d",
   "metadata": {},
   "source": [
    "We are interested in the \"Survived\" column, where are two possible outcomes: survived (1) or did not survive (0). We want to build a classifier to predict this outcome. Specifically, we are going to investigate how the passenger class, age and sex influenced survival.\n",
    "\n",
    "For passenger class, we are going to use dummy variables to represent the three possible states: binary variables which take on the value 0 if not true and 1 if true.\n",
    "\n",
    "Create dummy variables for classes 1 and 2. This implicitly means that the 3rd class will be the base case that we compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns based on conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff78cfa",
   "metadata": {},
   "source": [
    "Create a dummy variable equal to 1 if the passenger was female.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319baf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85529945",
   "metadata": {},
   "source": [
    "Clean up the data - drop all variables except for 'Class_1', 'Class_2',  'Sex' and 'Age', for our inputs and  'Survived' for our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24e642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48218e40",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Here we will create our own logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f10106",
   "metadata": {},
   "source": [
    "\n",
    "Write an R function for the logistic function: $\\theta = \\frac{1}{1 + \\exp(-x)}$. The function takes \\(x\\) as its sole argument. Plot the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42472e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b5d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83dece55",
   "metadata": {},
   "source": [
    "We are going to use the logistic function to represent the probability of a passenger surviving. But to do so, we need to write a function which returns the linear combination of $(\\beta_0 + \\beta_1 z_1 + \\beta_2 z_2)$. The function should take as inputs $ ( \\beta_0, \\beta_1, \\beta_2 )$ (the regression parameters) and the covariates $z_1$ and $z_2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combination(beta_0, beta_1, beta_2, z_1, z_2):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d64d4",
   "metadata": {},
   "source": [
    "Write a function which returns the probability:\n",
    "\n",
    "$$\\theta_i = Logistic(\\beta_0 + \\beta_1 * z_1 + \\beta_2 * z_2) $$\n",
    "\n",
    "where $Logistic$ is the function you created above. The function should takes as input $ ( \\beta_0, \\beta_1, \\beta_2 )$ (the regression parameters) and the covariates $z_1$ and $z_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(beta_0, beta_1, beta_2, z_1, z_2):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d042a46",
   "metadata": {},
   "source": [
    "We are now going to write a function which returns the log-likelihood for a single set, $i$ of data points: $(z_{1i}, z_{2i}, Si)$ where $S_i\\in{0,1}$ represents whether a passenger survived (1) or not (0). In logistic regression, we assume that $S_i \\sim Bernoulli(\\theta_i)$. This means that the likelihood, $L_i$, for a single set of data points is given by:\n",
    "\n",
    "$$ L_i = \\theta_i^{S_i} (1-\\theta_i)^{1-S_i} $$\n",
    "\n",
    "Write a function with takes as input $ ( \\beta_0, \\beta_1, \\beta_2 )$ (the regression parameters) and the covariates $z_1$ and $z_2$ and (crucially!) a value of $S_i$ and returns the likelihood $L_i$\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_i(S_i, beta_0, beta_1, beta_2, z_1, z_2):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb38472",
   "metadata": {},
   "source": [
    "The overall likelihood of observations is given by the product of the individual likelihoods of each data point, since we assume that the data are (conditionally) independent given the parameters:\n",
    "\n",
    "$$ L = \\prod_i^{N} L_i $$\n",
    "\n",
    "Write a function that takes as input your processed Titanic dataset and the parameters $\\beta_0, \\beta_1, \\beta_2$ \n",
    "and returns the likelihood. In calculating the likelihood, specify that $z_1$ and $z_2$ should be your class dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(beta_0, beta_1, beta_2, df):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0aabbb",
   "metadata": {},
   "source": [
    "We are now going to try to estimate the parameters $\\beta_0$ and $\\beta_1$ by doing a grid search. We start by fixing $\\beta_0=-1.14$  (this is the maximum likelihood value of the parameter). We are then going to do a grid search across all combinations of the following values of  $\\beta_1=(0,1,1.67,2,2.5)$ $\\beta_2=(−1,0,1,2,3)$. For each of the 25 combinations of both sets of parameters, calculate the likelihood. In doing so, find parameters that are close to the maximum likelihood values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = -1.14\n",
    "beta_1 = [0, 1, 1.67, 2, 2.5]\n",
    "beta_2 = [-1, 0, 1, 2, 3]\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487138ec",
   "metadata": {},
   "source": [
    "Find the values of `beta_1` and `beta_2` in the grid with the maximum likelihood (note, if you are using `np.argmax`, the output index will be flattened, `np.unravel_index` may be helpful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faea3e",
   "metadata": {},
   "source": [
    "Compare your results to the what you would get with [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f841a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "152e8965",
   "metadata": {},
   "source": [
    "What do your estimates suggest are the odds ratios for survival relative to 3rd class passengers for being in 1st and 2nd classes respectively?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70181bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270220ee",
   "metadata": {},
   "source": [
    "What does your model predict is the change in probability of survival in moving from 3rd to 2nd class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b65971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d078bb3e",
   "metadata": {},
   "source": [
    "What is the change in probability in moving from 2nd to 1st class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f660f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f631a2cb",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ba90b",
   "metadata": {},
   "source": [
    "We are going to build our own decision tree. We will use five variables here. For age, we are going to split the data up into three segments: (i) those aged 16 or less; (ii) those between 16 and 60; (iii) and those over 60. Create dummy variables for categories (i) and (iii). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516c59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951220b9",
   "metadata": {},
   "source": [
    "The entropy of a binary outcome variable, $X_i$, is given by:\n",
    "\n",
    "$$ H = p \\log p + (1-p) \\log (1-p) $$\n",
    "\n",
    "where $ p = \\Pr(X=1)$. \n",
    "\n",
    "\n",
    "Write a function which can calculate the entropy of a binary vector. Use it to calculate the entropy of the survival variable in the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09787ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate entropy\n",
    "def entropy(v_binary):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f1566",
   "metadata": {},
   "source": [
    "## Building a Decision Tree Classifier\n",
    "\n",
    "We now start to build a decision tree classifier. To do so, we are going to choose one of the five variables to split on based on the reduction in entropy this provides. To do so, we calculate the conditional entropy, $H(X|V) $, where $V $\n",
    "\n",
    "is a particular variable we have split on. At each step, we will choose the variable to split on so that it results in the greatest reduction in entropy.\n",
    "\n",
    "### Conditional Entropy for a Binary Variable\n",
    "\n",
    "The conditional entropy for a binary variable, $V$, is given by:\n",
    "\n",
    "$$\n",
    "H(X|V) = \\frac{S(V=1)}{S(\\varnothing)} \\times H(S(V=1)) + \\frac{S(V=0)}{S(\\varnothing)} \\times H(S(V=0)),\n",
    "$$\n",
    "\n",
    "where $S(V=v)$\n",
    "is the set of members of the random variable $X $ corresponding to$V=v$. For example, consider:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9422251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = pd.DataFrame({'X': [0, 1, 0, 1, 0, 1],\n",
    "                           'V': [1, 1, 1, 0, 0, 1]})\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e374030",
   "metadata": {},
   "source": [
    "then $S(V=1)$ is the $X$ column from the subsetted data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_example[df_example['V'] == 1]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9ad19",
   "metadata": {},
   "source": [
    "Write a function to calculate the conditional entropy of splitting on a particular variable for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeff9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(variable_name, df):\n",
    "    # Group by the given variable_name and calculate entropy for each group\n",
    "\n",
    "    # Calculate the probabilities (ps)\n",
    "\n",
    "    # Return the weighted sum of entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3ce59",
   "metadata": {},
   "source": [
    "Use the function you created in the previous question to determine the reduction in entropy from splitting on each of the five possible variables. Which column yields the greatest reduction in entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c33d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names except the first one\n",
    "\n",
    "# Calculate entropy reduction for each variable\n",
    "\n",
    "# Create the result DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068710c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entropy_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f2368",
   "metadata": {},
   "source": [
    "\n",
    "Explain intuitively why splitting on that variable resulted in the greatest reduction in entropy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cd4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a7e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "721c8ef9",
   "metadata": {},
   "source": [
    "Create a decision tree classifier using the variable you have identified. The classifier outputs a classification probability:\n",
    "$$ \\Pr (X=1|V=v)=\\frac{1}{S(V=v)}\\sum_{i\\in S(V=v)} X_i $$\n",
    "\n",
    "where $X$ denotes the survival variable and $V$ denotes the variable you split on. The above just means your outputted probability of survival is the corresponding fraction surviving in the subset corresponding to that particular value of the variable $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84afed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the depth_one_classifier function in Python\n",
    "def depth_one_classifier( ):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e549cf",
   "metadata": {},
   "source": [
    "Create a decision tree classifier with depth 2 (i.e. it splits on two variables), where in each step it chooses which variable to split on based on the greatest reduction in entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811c247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1ce9fcf",
   "metadata": {},
   "source": [
    "We now consider splitting on another of the remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55299ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8426e8a",
   "metadata": {},
   "source": [
    "So, we next split on the class_1 variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6055d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_two_classifier(  ):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ea8c9",
   "metadata": {},
   "source": [
    "Use your classifier to output the probabilities of survival for each (type of) individual in your dataset. Which groups have the highest survival probabilities and the lowest survival probabilities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07811d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3634b594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86f14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
