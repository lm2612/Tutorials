{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8034f230",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lm2612/Tutorials/blob/main/2_supervised_learning_classification/2-Classification_Titanic.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c259f",
   "metadata": {},
   "source": [
    "# Titanic: Machine learning from disaster\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this tutorial, we will use passenger data to predict who survived the shipwreck and also use our predictive model to answer the question: \"what sorts of people were more likely to survive?\". We will focus on passenger age, gender and socio-economic class). You can read more about the Titanic dataset [here](https://www.kaggle.com/c/titanic/overview).\n",
    "\n",
    "First, import packages and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73896b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5161a935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook running locally. Using local filepath = ./titanic.csv\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    filepath = \"https://raw.githubusercontent.com/lm2612/Tutorials/refs/heads/main/2_supervised_learning_classification/titanic.csv\"\n",
    "    print(f\"Notebook running in google colab. Using raw github filepath = {filepath}\")\n",
    "\n",
    "else:\n",
    "    filepath = \"./titanic.csv\"\n",
    "    print(f\"Notebook running locally. Using local filepath = {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717deb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d726a57",
   "metadata": {},
   "source": [
    "We are interested in the \"Survived\" column, where are two possible outcomes: survived (1) or did not survive (0). We want to build a classifier to predict this outcome. In this tutorial, we are going to compare different classification methods, where we try to determine the factors that influence whether a passenger survived. \n",
    "Specifically, we are going to investigate how the passenger class, age and sex influenced survival.\n",
    "\n",
    "For passenger class, we are going to use dummy variables to represent the three possible states: binary variables which take on the value 0 if not true and 1 if true.\n",
    "\n",
    "Create dummy variables for classes 1 and 2. This implicitly means that the 3rd class will be the base case that we compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152ef29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff78cfa",
   "metadata": {},
   "source": [
    "Create a dummy variable equal to 1 if the passenger was female.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319baf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c40c8f6",
   "metadata": {},
   "source": [
    "Clean up the data - drop all variables except for the 'Age', 'Sex', 'Pclass' for our inputs and  'Survived' for our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6ded9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0e0cf5a",
   "metadata": {},
   "source": [
    "Split the data into training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb30d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85a98800",
   "metadata": {},
   "source": [
    "Set up your X and y variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dd29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8e4a6a9",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "We will use the `sklearn.linear_model.LogisticRegression`. Read the docs here: https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f314a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set up and fit the logistic regression model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d103e33",
   "metadata": {},
   "source": [
    "What variable is given the most relevance for a prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c91ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0925fab9",
   "metadata": {},
   "source": [
    "## Validating our classification model\n",
    "Predict on the validation dataset and estimate accuracy using one of the classification metrics from [here](https://scikit-learn.org/1.5/modules/model_evaluation.html#classification-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7eacd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4707767",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "\n",
    "Now build decision tree using `sklearn.tree.DecisionTreeClassifier` using the docs here: https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier. Use the entropy criterion for splitting we discussed during lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12654fe",
   "metadata": {},
   "source": [
    "How does the decision tree compare against the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d349c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24ae92e",
   "metadata": {},
   "source": [
    "## Visualising how good the model is\n",
    "We can look at how often the models produce false positives and false negatives using a [confusion matrix](https://scikit-learn.org/1.5/auto_examples/model_selection/plot_confusion_matrix.html). It shows:\n",
    "\n",
    "\n",
    "```\n",
    "                           | Predicted Negatives (0) | Predicted Positives (1) |\n",
    "--------------------------------------------------------------------------------\n",
    "True Negatives (0)         | True Negatives          | False Positives         |\n",
    "True Positives (1)         | False Negatives         | True Positives          |\n",
    "```\n",
    "\n",
    "We want higher values along the upper left to lower right diagonal (more true negatives / true positives) and lower values in the opposite diagonal (fewer false negatives / false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aeb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compare the confusion matrices on the validation data for the regression and tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e28f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ab16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
